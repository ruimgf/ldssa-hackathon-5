{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import hashlib\n",
    "import numpy as np\n",
    "\n",
    "# recommendations\n",
    "import surprise\n",
    "from surprise import Dataset, Reader\n",
    "from surprise.model_selection import train_test_split, cross_validate, GridSearchCV\n",
    "from surprise.prediction_algorithms import BaselineOnly, KNNBaseline, Prediction\n",
    "from surprise import SVD\n",
    "\n",
    "# metrics\n",
    "import ml_metrics as metrics\n",
    "\n",
    "# eda\n",
    "from data_utils import describe, transformers\n",
    "\n",
    "# visualization\n",
    "from matplotlib import pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 453776\r\n",
      "drwxr-xr-x  11 sofiacardita  staff   374B Aug 26 10:04 \u001b[1m\u001b[36m.\u001b[m\u001b[m\r\n",
      "drwxr-xr-x   9 sofiacardita  staff   306B Aug 26 10:34 \u001b[1m\u001b[36m..\u001b[m\u001b[m\r\n",
      "-rw-r--r--@  1 sofiacardita  staff   6.0K Aug 26 10:04 .DS_Store\r\n",
      "-rw-r--r--   1 sofiacardita  staff   6.6K Aug 26 09:55 example_output.csv\r\n",
      "-rw-r--r--   1 sofiacardita  staff    77M Jul 28 12:30 song_tag.csv\r\n",
      "-rw-r--r--   1 sofiacardita  staff    19M Aug 26 09:55 song_tag.zip\r\n",
      "-rw-r--r--   1 sofiacardita  staff   9.5M Aug 26 09:55 songs.txt\r\n",
      "-rw-r--r--   1 sofiacardita  staff    12M Aug 26 09:55 tags.csv\r\n",
      "-rw-r--r--   1 sofiacardita  staff   400K Aug 26 09:55 test_users.csv\r\n",
      "-rw-r--r--   1 sofiacardita  staff    86M Mar 11  2012 train_play_counts.txt\r\n",
      "-rw-r--r--   1 sofiacardita  staff    18M Aug 26 09:55 train_play_counts.zip\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lah data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fd50c4007b68a3737fe052d5a4f78ce8aa117f3d\tSOBONKR12A58A7A7E0\t1\r\n",
      "fd50c4007b68a3737fe052d5a4f78ce8aa117f3d\tSOEGIYH12A6D4FC0E3\t1\r\n",
      "fd50c4007b68a3737fe052d5a4f78ce8aa117f3d\tSOFLJQZ12A6D4FADA6\t1\r\n",
      "fd50c4007b68a3737fe052d5a4f78ce8aa117f3d\tSOHTKMO12AB01843B0\t1\r\n",
      "fd50c4007b68a3737fe052d5a4f78ce8aa117f3d\tSODQZCY12A6D4F9D11\t1\r\n",
      "fd50c4007b68a3737fe052d5a4f78ce8aa117f3d\tSOXLOQG12AF72A2D55\t1\r\n",
      "d7083f5e1d50c264277d624340edaaf3dc16095b\tSOUVUHC12A67020E3B\t1\r\n",
      "d7083f5e1d50c264277d624340edaaf3dc16095b\tSOUQERE12A58A75633\t1\r\n",
      "d7083f5e1d50c264277d624340edaaf3dc16095b\tSOIPJAX12A8C141A2D\t1\r\n",
      "d7083f5e1d50c264277d624340edaaf3dc16095b\tSOEFCDJ12AB0185FA0\t2\r\n"
     ]
    }
   ],
   "source": [
    "!head data/train_play_counts.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SOAAADD12AB018A9DD 1\r\n",
      "SOAAADE12A6D4F80CC 2\r\n",
      "SOAAADF12A8C13DF62 3\r\n",
      "SOAAADZ12A8C1334FB 4\r\n",
      "SOAAAFI12A6D4F9C66 5\r\n",
      "SOAAAGK12AB0189572 6\r\n",
      "SOAAAGN12AB017D672 7\r\n",
      "SOAAAGO12A67AE0A0E 8\r\n",
      "SOAAAGP12A6D4F7D1C 9\r\n",
      "SOAAAGQ12A8C1420C8 10\r\n"
     ]
    }
   ],
   "source": [
    "!head data/songs.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_ratings(path):\n",
    "\n",
    "    users = make_users()\n",
    "    items = make_items()\n",
    "\n",
    "    #users_ = read_array_from_csv(path, 'object', 0, delimiter=\"\\t\")\n",
    "    items_ = read_array_from_csv(path, 'object', 1)\n",
    "\n",
    "    rows = make_rows(users)\n",
    "    cols = make_cols(items, items_)\n",
    "\n",
    "    nrows = users.shape[0]\n",
    "    ncols = items.shape[0]\n",
    "\n",
    "    shape = (nrows, ncols)\n",
    "\n",
    "    data = np.ones(rows.size)\n",
    "\n",
    "    return coo_matrix((data, (rows, cols)), shape=shape)\n",
    "\n",
    "\n",
    "def make_users():\n",
    "    path = os.path.join('data', 'train_play_counts.txt')\n",
    "    users = read_array_from_csv(path, 'object', 0, delimiter=\"\\t\")\n",
    "    return users[users.argsort()]\n",
    "\n",
    "\n",
    "def make_items():\n",
    "    path = os.path.join('data', 'songs.txt')\n",
    "    items = read_array_from_csv(path, 'object', 0, delimiter=\" \")\n",
    "    return items[items.argsort()]\n",
    "\n",
    "\n",
    "def read_array_from_csv(path, dtype, column, delimiter=\" \"):\n",
    "    return np.genfromtxt(path, dtype=dtype, skip_header=False, usecols=[column],\n",
    "                         delimiter=delimiter)\n",
    "\n",
    "def make_rows(users):\n",
    "    rows = np.unique(users)\n",
    "    #rows = [np.argwhere(users == u)[0, 0] for u in users_]\n",
    "    return rows\n",
    "\n",
    "\n",
    "def make_cols(items, items_):\n",
    "    cols = [np.argwhere(items == i)[0, 0] for i in items_]\n",
    "    return np.array(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = make_ratings(\"data/train_play_counts.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'SOAAADD12AB018A9DD'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = os.path.join('data', 'songs.txt')\n",
    "items = read_array_from_csv(path, 'object', 0, delimiter=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With surprise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(file, explore=False, delimeter=\" \", names=[]):\n",
    "    ds = pd.read_csv(file, sep=delimeter, names=names, header=0)\n",
    "    if explore:\n",
    "        describe.describe_data(ds, file)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Describing 'data/songs.txt'\n",
      "type:  class 'pandas.core.frame.DataFrame'\n",
      "shape:  (386212, 2)\n",
      ".dtypes:\n",
      "0. iid : object (total_values: 386212; values: -) (nans: 0) -------- Object!!\n",
      "1. item_index : int64 (total_values: 386212; values: -) (nans: 0)\n",
      "Total nans 0\n",
      ".index.names:  [None]\n",
      "Describing 'data/train_play_counts.txt'\n",
      "type:  class 'pandas.core.frame.DataFrame'\n",
      "shape:  (1450932, 3)\n",
      ".dtypes:\n",
      "0. uid : object (total_values: 110000; values: -) (nans: 0) -------- Object!!\n",
      "1. iid : object (total_values: 163206; values: -) (nans: 0) -------- Object!!\n",
      "2. totals : int64 (total_values: 299; values: -) (nans: 0)\n",
      "Total nans 0\n",
      ".index.names:  [None]\n"
     ]
    }
   ],
   "source": [
    "items = load_file(\"data/songs.txt\", explore=True, delimeter=\" \", names=[\"iid\", \"item_index\"])\n",
    "ratings = load_file(\"data/train_play_counts.txt\", explore=True, delimeter=\"\\t\", names=[\"uid\", \"iid\", \"totals\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>iid</th>\n",
       "      <th>totals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fd50c4007b68a3737fe052d5a4f78ce8aa117f3d</td>\n",
       "      <td>SOEGIYH12A6D4FC0E3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fd50c4007b68a3737fe052d5a4f78ce8aa117f3d</td>\n",
       "      <td>SOFLJQZ12A6D4FADA6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fd50c4007b68a3737fe052d5a4f78ce8aa117f3d</td>\n",
       "      <td>SOHTKMO12AB01843B0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fd50c4007b68a3737fe052d5a4f78ce8aa117f3d</td>\n",
       "      <td>SODQZCY12A6D4F9D11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fd50c4007b68a3737fe052d5a4f78ce8aa117f3d</td>\n",
       "      <td>SOXLOQG12AF72A2D55</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        uid                 iid  totals\n",
       "0  fd50c4007b68a3737fe052d5a4f78ce8aa117f3d  SOEGIYH12A6D4FC0E3       1\n",
       "1  fd50c4007b68a3737fe052d5a4f78ce8aa117f3d  SOFLJQZ12A6D4FADA6       1\n",
       "2  fd50c4007b68a3737fe052d5a4f78ce8aa117f3d  SOHTKMO12AB01843B0       1\n",
       "3  fd50c4007b68a3737fe052d5a4f78ce8aa117f3d  SODQZCY12A6D4F9D11       1\n",
       "4  fd50c4007b68a3737fe052d5a4f78ce8aa117f3d  SOXLOQG12AF72A2D55       1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = ratings.drop_duplicates()\n",
    "items = items.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 923)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rscale = (ratings.totals.min(),ratings.totals.max())\n",
    "rscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_dataset(ratings, rscale):\n",
    "    # A reader is still needed but only the rating_scale param is requiered.\n",
    "    reader = Reader(rating_scale=rscale) # see df.col.hist()\n",
    "\n",
    "    # The columns must correspond to user id, item id and ratings (in that order).\n",
    "    data = Dataset.load_from_df(ratings[['uid', 'iid', 'totals']], reader)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = prep_dataset(ratings, rscale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse: 7.004295561788455\n",
      "mae: 2.909209271160712\n"
     ]
    }
   ],
   "source": [
    "def baseline_cross_validate(data, bsl_options=None, cv=5):\n",
    "    if not bsl_options:\n",
    "        bsl_options = {'method': 'sgd', 'learning_rate': 0.00005, 'reg': 0.05}\n",
    "    \n",
    "    baseline = BaselineOnly(bsl_options=bsl_options)\n",
    "    \n",
    "    res = cross_validate(baseline, data, measures=['RMSE', 'MAE'], cv=cv, n_jobs=-1)\n",
    "    print(\"rmse: %s\" % res[\"test_rmse\"].mean())\n",
    "    print(\"mae: %s\" % res[\"test_mae\"].mean())\n",
    "    return baseline, res\n",
    "\n",
    "\n",
    "# You must decide whether or not to use a `Dataset` or a `Trainset`.\n",
    "baseline, baseline_results = baseline_cross_validate(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using sgd...\n"
     ]
    }
   ],
   "source": [
    "def make_predictions(algo, ratings_train):\n",
    "    \n",
    "    \n",
    "    algo.fit(ratings_train)\n",
    "    \n",
    "    test_set = ratings_train.build_anti_testset()\n",
    "    \n",
    "    preds = algo.test(test_set)\n",
    "    return algo, preds\n",
    "\n",
    "    \n",
    "model, preds = make_predictions(baseline, data.build_full_trainset())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n(predictions, n=500):\n",
    "    '''Return the top-N recommendation for each user from a set of predictions.\n",
    "\n",
    "    Args:\n",
    "        predictions(list of Prediction objects): The list of predictions, as\n",
    "            returned by the test method of an algorithm.\n",
    "        n(int): The number of recommendation to output for each user. Default\n",
    "            is 10.\n",
    "\n",
    "    Returns:\n",
    "    A dict where keys are user (raw) ids and values are lists of tuples:\n",
    "        [(raw item id, rating estimation), ...] of size n.\n",
    "    '''\n",
    "\n",
    "    # First map the predictions to each user.\n",
    "    top_n = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        top_n[uid].append((iid, est))\n",
    "\n",
    "    # Then sort the predictions for each user and retrieve the k highest ones.\n",
    "    for uid, user_ratings in top_n.items():\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = user_ratings[:n]\n",
    "\n",
    "    return top_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_csv(top_n, filename=\"preds.csv\"):\n",
    "    users = []\n",
    "    for uid, recs in top_n.items():\n",
    "        items = [rec[0] for rec in recs]\n",
    "        urec = (uid, items)\n",
    "        users.append(urec)\n",
    "    # sort by user\n",
    "    recommendations = sorted(users, key=lambda x: x[0])\n",
    "    \n",
    "    # do csv\n",
    "    # User, songid songid \n",
    "    s = \"User: \\n\"\n",
    "    for rec in recommendations:\n",
    "        user = str(rec[0])\n",
    "        recs = \" \".join(str(r) for r in rec[1])\n",
    "        s += \"{user},{recs}\\n\".format(user=user, recs=recs)\n",
    "    #print(s)\n",
    "    with open(filename,'w') as f:\n",
    "        f.write(s)\n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
